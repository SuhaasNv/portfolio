<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DocuMind (Insight Garden) Case Study | Document RAG SaaS</title>
    <meta name="description" content="DocuMind is a full-stack document RAG SaaS: upload PDFs, chat with your documents via streaming AI, with source attribution. React, NestJS, pgvector, BullMQ. Deployed on Vercel, Railway, Supabase, Upstash.">
    <link rel="icon" type="image/png" href="../images/Suhaas Nv.png">
    <link rel="shortcut icon" type="image/png" href="../images/Suhaas Nv.png">
    <link rel="apple-touch-icon" href="../images/Suhaas Nv.png">
    <link rel="stylesheet" href="../style.css">
    <script src="https://kit.fontawesome.com/c8ea7cd38e.js" crossorigin="anonymous"></script>
    <style>
        .case-study-container {
            max-width: 900px;
            margin: 0 auto;
            padding: 40px 20px;
            color: #ababab;
        }
        .case-study-header {
            margin-bottom: 40px;
        }
        .case-study-title {
            font-size: 48px;
            font-weight: 600;
            color: #fff;
            margin-bottom: 16px;
        }
        .case-study-subtitle {
            font-size: 20px;
            color: #ababab;
            line-height: 1.6;
            margin-bottom: 30px;
        }
        .back-link {
            display: inline-block;
            color: #ff004f;
            text-decoration: none;
            font-size: 16px;
            margin-bottom: 30px;
            transition: color 0.3s;
        }
        .back-link:hover {
            color: #fff;
        }
        .case-study-live-link-wrap {
            margin: 0 0 30px;
        }
        .case-study-link-sep {
            color: #666;
            margin: 0 8px;
        }
        .case-study-live-link {
            display: inline-block;
            color: #ff004f;
            text-decoration: none;
            font-size: 16px;
            font-weight: 500;
            transition: color 0.3s;
        }
        .case-study-live-link:hover {
            color: #fff;
        }
        .case-study-section {
            margin-bottom: 50px;
        }
        .case-study-section h2 {
            font-size: 32px;
            font-weight: 600;
            color: #fff;
            margin-bottom: 20px;
        }
        .case-study-section p {
            line-height: 1.8;
            margin-bottom: 16px;
            font-size: 16px;
        }
        .case-study-section strong {
            color: #fff;
            font-weight: 600;
        }
        .tldr {
            font-size: 17px;
            color: #fff;
            font-weight: 500;
            margin-bottom: 16px;
            padding-bottom: 12px;
            border-bottom: 1px solid #262626;
        }
        .case-study-hero-image {
            width: 100%;
            margin: 40px 0 50px;
            border-radius: 10px;
            overflow: hidden;
        }
        .case-study-hero-image img {
            width: 100%;
            height: auto;
            display: block;
            border-radius: 10px;
        }
        .hero-image-clickable {
            cursor: pointer;
            transition: opacity 0.2s ease;
        }
        .hero-image-clickable:hover {
            opacity: 0.85;
        }
        .hero-image-clickable:focus {
            outline: 2px solid #ff004f;
            outline-offset: 4px;
            border-radius: 4px;
        }
        /* Image Lightbox */
        .image-lightbox {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 10000;
            display: none;
            align-items: center;
            justify-content: center;
            opacity: 0;
            transition: opacity 0.25s ease;
            pointer-events: none;
        }
        .image-lightbox:not([hidden]) {
            display: flex;
            opacity: 1;
            pointer-events: all;
        }
        .lightbox-backdrop {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.92);
            cursor: pointer;
        }
        .lightbox-close {
            position: absolute;
            top: 20px;
            right: 30px;
            background: rgba(255, 255, 255, 0.15);
            border: none;
            color: #fff;
            font-size: 36px;
            font-weight: 300;
            width: 48px;
            height: 48px;
            border-radius: 50%;
            cursor: pointer;
            z-index: 10001;
            display: flex;
            align-items: center;
            justify-content: center;
            line-height: 1;
            padding: 0;
            transition: background 0.2s ease;
            font-family: Arial, sans-serif;
        }
        .lightbox-close:hover,
        .lightbox-close:focus {
            background: rgba(255, 255, 255, 0.25);
            outline: 2px solid #ff004f;
            outline-offset: 2px;
        }
        .lightbox-image {
            position: relative;
            max-width: 90%;
            max-height: 90vh;
            object-fit: contain;
            border-radius: 8px;
            z-index: 10001;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.5);
        }
        @media (prefers-reduced-motion: reduce) {
            .image-lightbox {
                transition: none;
            }
            .hero-image-clickable {
                transition: none;
            }
            .lightbox-close {
                transition: none;
            }
        }
        @media only screen and (max-width: 600px) {
            .lightbox-close {
                top: 15px;
                right: 20px;
                width: 44px;
                height: 44px;
                font-size: 32px;
            }
            .lightbox-image {
                max-width: 95%;
                max-height: 85vh;
            }
        }
        .case-study-tldr-box {
            background: rgba(255, 255, 255, 0.03);
            border-left: 3px solid #ff004f;
            padding: 24px;
            margin: 40px 0 50px;
            border-radius: 6px;
        }
        .case-study-tldr-box h3 {
            font-size: 20px;
            font-weight: 600;
            color: #fff;
            margin-bottom: 16px;
            margin-top: 0;
        }
        .case-study-tldr-box ul {
            margin: 0;
            padding-left: 20px;
            list-style: none;
        }
        .case-study-tldr-box ul li {
            margin-bottom: 12px;
            line-height: 1.6;
            position: relative;
            padding-left: 20px;
        }
        .case-study-tldr-box ul li::before {
            content: '▸';
            color: #ff004f;
            position: absolute;
            left: 0;
        }
        .case-study-tldr-box ul li:last-child {
            margin-bottom: 0;
        }
        .case-study-image-row {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 24px;
            margin: 30px 0 40px;
        }
        .case-study-image-row-3 {
            grid-template-columns: 1fr 1fr 1fr;
        }
        .case-study-image-fig {
            margin: 0;
        }
        .case-study-image-fig img {
            width: 100%;
            height: auto;
            border-radius: 8px;
            display: block;
        }
        .case-study-image-fig .hero-image-clickable {
            cursor: pointer;
            transition: opacity 0.2s ease;
        }
        .case-study-image-fig .hero-image-clickable:hover {
            opacity: 0.9;
        }
        .case-study-image-fig figcaption {
            margin-top: 12px;
            font-size: 14px;
            line-height: 1.5;
            color: #888;
        }
        @media only screen and (max-width: 600px) {
            .case-study-image-row,
            .case-study-image-row-3 {
                grid-template-columns: 1fr;
                gap: 20px;
                margin: 20px 0 30px;
            }
            .case-study-image-fig figcaption {
                font-size: 13px;
            }
            .case-study-container {
                padding: 20px 15px;
            }
            .case-study-title {
                font-size: 32px;
            }
            .case-study-subtitle {
                font-size: 18px;
            }
            .case-study-section h2 {
                font-size: 24px;
            }
            .case-study-section p {
                font-size: 14px;
            }
            .case-study-hero-image {
                margin: 30px 0 40px;
            }
            .case-study-tldr-box {
                padding: 20px;
                margin: 30px 0 40px;
            }
            .case-study-tldr-box h3 {
                font-size: 18px;
                margin-bottom: 12px;
            }
            .case-study-tldr-box ul li {
                font-size: 14px;
                margin-bottom: 10px;
            }
        }
    </style>
</head>
<body>
    <div class="case-study-container">
        <a href="../index.html#portfolio" class="back-link">← Back to Work</a>
        
        <div class="case-study-header">
            <h1 class="case-study-title">DocuMind (Insight Garden)</h1>
            <p class="case-study-subtitle">A full-stack document RAG SaaS: upload PDFs, analyse them with AI, and chat with your documents via streaming answers—with source attribution and no hallucinations.</p>
            <p class="case-study-live-link-wrap"><a href="https://docu-mind-delta.vercel.app/" target="_blank" rel="noopener noreferrer" class="case-study-live-link">Check demo</a> <span class="case-study-link-sep">·</span> <a href="https://github.com/SuhaasNv/DocuMind" target="_blank" rel="noopener noreferrer" class="case-study-live-link">GitHub</a></p>
        </div>

        <div class="case-study-hero-image">
            <img src="../images/work-5.png" alt="DocuMind landing: Ask questions to your documents. Get grounded, source-based answers." class="hero-image-clickable" id="heroImage" tabindex="0" role="button" aria-label="Click to view full-size image">
        </div>
        
        <!-- Image Lightbox Modal -->
        <div id="imageLightbox" class="image-lightbox" role="dialog" aria-modal="true" aria-labelledby="lightboxImage" hidden>
            <div class="lightbox-backdrop"></div>
            <button class="lightbox-close" aria-label="Close image viewer" tabindex="0">&times;</button>
            <img id="lightboxImage" class="lightbox-image" src="" alt="" tabindex="0">
        </div>

        <div class="case-study-tldr-box">
            <h3>In a nutshell</h3>
            <ul>
                <li>Full-stack document RAG: users upload PDFs, the system chunks and embeds them for analysis; users then query and analyse their documents via streaming AI—with source attribution.</li>
                <li>User auth (JWT), document upload (drag-and-drop, 50MB), async processing with progress, and per-document chat to analyse content with optional “show sources.”</li>
                <li>Hybrid retrieval (pgvector + lexical), configurable LLM/embedding providers (Ollama, OpenAI, Gemini, stub). SSE streaming for chat; frontend polls for processing status.</li>
                <li>Deployed: frontend on <strong>Vercel</strong>, backend on <strong>Railway</strong>, database on <strong>Supabase</strong>, Redis on <strong>Upstash</strong>.</li>
            </ul>
        </div>

        <section class="case-study-section case-study-screens">
            <h2>In the app</h2>
            <p class="tldr">Sign in, upload your PDFs, and analyse them in under a minute—processing runs in the background so you can start chatting as soon as a document is ready.</p>
            <div class="case-study-image-row">
                <figure class="case-study-image-fig">
                    <img src="../images/work-5.1.png" alt="DocuMind login: Welcome back, sign in to continue to your documents." class="hero-image-clickable" tabindex="0" role="button" aria-label="Open image in lightbox">
                    <figcaption>Sign in — JWT-based auth and protected routes so your documents stay yours.</figcaption>
                </figure>
                <figure class="case-study-image-fig">
                    <img src="../images/work-5.2.png" alt="DocuMind Documents: Upload a document, drag and drop or choose PDF, up to 50MB. Your documents list and processing in the background." class="hero-image-clickable" tabindex="0" role="button" aria-label="Open image in lightbox">
                    <figcaption>Documents — Upload PDFs (drag-and-drop or picker, 50MB). We process in the background; you can analyse and chat with a document in under a minute.</figcaption>
                </figure>
            </div>
            <div class="case-study-image-row case-study-image-row-3">
                <figure class="case-study-image-fig">
                    <img src="../images/work-5.3.png" alt="DocuMind: Document uploading with progress bar and Processing status." class="hero-image-clickable" tabindex="0" role="button" aria-label="Open image in lightbox">
                    <figcaption>Uploading — Processing runs in the background with a progress bar; you see status until the document is ready.</figcaption>
                </figure>
                <figure class="case-study-image-fig">
                    <img src="../images/work-5.4.png" alt="DocuMind: Document ready with Ready badge and Chat button." class="hero-image-clickable" tabindex="0" role="button" aria-label="Open image in lightbox">
                    <figcaption>Ready — Once processing is done, the document shows a Ready badge and you can open Chat.</figcaption>
                </figure>
                <figure class="case-study-image-fig">
                    <img src="../images/work-5.5.png" alt="DocuMind Chat: Ask questions and get answers grounded in your document with source citations." class="hero-image-clickable" tabindex="0" role="button" aria-label="Open image in lightbox">
                    <figcaption>Chat — Ask questions and get answers grounded in your document, with optional source citations (chunk indices).</figcaption>
                </figure>
            </div>
        </section>

        <section class="case-study-section">
            <h2>What it is</h2>
            <p class="tldr">DocuMind turns your PDFs into a conversation. Upload, wait for processing, then ask questions and analyse your documents. Answers come only from your documents—no guesswork, no external leakage.</p>
            <p><strong>DocuMind</strong> is a document RAG (Retrieval-Augmented Generation) app. Users sign up, upload PDFs, and analyse and chat with their documents. The system chunks and embeds each PDF into a vector database; when you ask a question, it finds the relevant bits, builds a grounded prompt, and streams the answer back. You can toggle “show sources” to see which chunks and scores backed the reply.</p>
            <p>I built it to show how a real RAG product hangs together end-to-end: auth, upload, async processing, progress feedback, and streaming chat—with clear ownership of data and configurable AI providers. The value proposition is simple: <strong>ask questions to your documents; get grounded, source-based answers</strong>. No hallucinations, no pulling from the open web.</p>
        </section>

        <section class="case-study-section">
            <h2>What it does for users</h2>
            <p class="tldr">Register and log in, upload PDFs (drag-and-drop or picker), watch processing progress, then analyse and chat per document with optional source citations.</p>
            <p>Users get <strong>auth</strong> (register/login with JWT, optional persistence and protected routes so the app doesn’t flash logged-out content). They get <strong>document upload</strong> via drag-and-drop or file picker, with a 50MB limit and server-side checks. Processing runs in the background: BullMQ + Redis job queue, PDF → text → chunk → embed → store in PostgreSQL with pgvector. The UI polls every couple of seconds and shows a progress bar and status (PENDING → PROCESSING → DONE or FAILED).</p>
            <p>Once a document is ready, users open <strong>per-document chat</strong> to analyse it. They type a question; the backend embeds it, does hybrid retrieval (dense vectors + lexical search), builds a RAG prompt, and streams the answer over SSE. They can turn on “show sources” to see which chunks and scores were used. Settings let them tweak things like auto-scroll, show sources, and animations; account and system info (backend URL, version) are available where it makes sense. Health checks and clear error handling cover auth, network, and API failures so the app stays predictable in production.</p>
        </section>

        <section class="case-study-section">
            <h2>How it’s built</h2>
            <p class="tldr">React (Vite, TypeScript, Zustand, shadcn/ui) on the front end; NestJS (Prisma, pgvector, BullMQ, Redis) on the back. Streaming chat over SSE; progress via polling.</p>
            <p>The <strong>front end</strong> is a React SPA: Vite 5, TypeScript 5, React 18, React Router 6 for public and protected routes. State lives in Zustand (auth, documents, conversations, UI preferences), with persistence for auth and prefs and a hydration gate so protected routes don’t flash before the app knows if you’re logged in. Styling is Tailwind and shadcn/ui (Radix); animations use Framer Motion with reduced-motion support. Chat streams via native <code>fetch</code> and <code>ReadableStream</code>; forms use React Hook Form and Zod; markdown in chat is react-markdown.</p>
            <p>The <strong>back end</strong> is NestJS 11 on Node (TypeScript 5): REST for most APIs, SSE for <code>/documents/:id/chat/stream</code>. Auth is JWT (Passport + passport-jwt), passwords hashed with bcrypt; a global JWT guard plus <code>@Public()</code> for auth and health. Validation is class-validator/class-transformer with a global ValidationPipe. Data lives in PostgreSQL with Prisma 7; vectors in pgvector (raw SQL for the vector column). Document processing jobs run in BullMQ with Redis; PDF text comes from pdf-parse. Embeddings and LLM are configurable (stub or OpenAI for embeddings; stub, Ollama, OpenAI, or Gemini for the LLM), so the same RAG pipeline can swap providers via env.</p>
            <p><strong>Flow</strong>: Upload hits <code>POST /documents/upload</code>; the backend creates a Document (PENDING), stores the file, and enqueues a job. The worker extracts text, chunks (e.g. 900 chars, 100 overlap), embeds, and writes to <code>document_chunks</code> with progress (0 → 30 → 30–90 → 100). The front end polls <code>GET /documents/:id</code> and shows status. For chat, the client calls <code>POST /documents/:id/chat/stream</code> with <code>{ question }</code>; the backend checks ownership and DONE status, embeds the question, runs hybrid retrieval (pgvector + lexical), builds the RAG prompt, and streams tokens over SSE with <code>delta</code> and <code>done</code> (and optional sources).</p>
        </section>

        <section class="case-study-section">
            <h2>Where it runs</h2>
            <p class="tldr">Frontend on Vercel, backend on Railway, database on Supabase, Redis on Upstash. Split stack, env-driven config.</p>
            <p>The app is deployed as a <strong>split stack</strong>: the React app on <strong>Vercel</strong> (with <code>VITE_API_URL</code> pointing at the backend), the NestJS API on <strong>Railway</strong>, PostgreSQL + pgvector on <strong>Supabase</strong>, and Redis (BullMQ) on <strong>Upstash</strong>. CORS, env vars, and runtime config for the production API URL are documented so the front end always talks to the right backend. Local dev uses Docker for Postgres and Redis; full deployment steps and sanity checks live in the repo docs.</p>
        </section>

        <section class="case-study-section">
            <h2>Standout technical choices</h2>
            <p class="tldr">SSE with POST + Bearer auth, hybrid retrieval, protected routes that wait for hydration, and configurable LLM/embeddings so the pipeline isn’t tied to one vendor.</p>
            <p><strong>Streaming chat with POST and auth.</strong> Chat uses <code>fetch</code> + <code>ReadableStream</code>, not EventSource, so the request can be a POST with a JSON body and <code>Authorization: Bearer</code>. The backend supports <code>?token=</code> for proxies where needed. The client aborts the stream on logout or unmount so there are no dangling connections.</p>
            <p><strong>Hybrid retrieval.</strong> Answers are grounded in both dense (pgvector) and lexical (keyword) retrieval, merged and re-ranked. That often beats pure vector search for mixed query types and keeps relevance high.</p>
            <p><strong>Protected routes and hydration.</strong> The front end waits for Zustand persistence to hydrate before deciding whether to show the app or redirect to login. That avoids the flash of dashboard content for unauthenticated users.</p>
            <p><strong>Configurable LLM and embeddings.</strong> Stub, Ollama, OpenAI, and Gemini plug into the same RAG pipeline; embeddings can be stub or OpenAI. Swap via env—no code change for trying a new model.</p>
            <p><strong>Progress and status.</strong> Document processing reports numeric progress (0 → 30 → 30–90 → 100) and status (PENDING → PROCESSING → DONE/FAILED). The UI polls and shows a progress bar; when a document is DONE, users can go straight to chat.</p>
        </section>

        <section class="case-study-section">
            <h2>What I implemented</h2>
            <p class="tldr">End-to-end: auth, documents (upload, CRUD, processing jobs), chunks with pgvector, embedding and RAG modules, hybrid retrieval, SSE streaming, health checks, and a React app with dashboard, chat, and settings.</p>
            <p>On the <strong>back end</strong>: Auth (register/login, JWT, bcrypt, DTOs, startup validation of JWT secret). Documents (upload with Multer, CRUD, ownership checks, status and progress). Chunks (insert/delete, raw SQL for pgvector). Embedding module (single interface: stub or OpenAI). Retrieval service (hybrid pgvector + lexical, merge and re-rank, ownership and DONE enforcement). RAG module (prompt building, LLM service with stub/Ollama/OpenAI/Gemini, streaming and non-streaming, latency logging). Jobs module (BullMQ processor: PDF → text → chunk → embed → store; progress updates). Health (<code>GET /health</code>). Common pieces: <code>@Public()</code>, <code>@CurrentUser()</code>, global exception filter, CORS and ValidationPipe. SSE stream endpoint with Bearer (and optional query) auth and abort on client disconnect.</p>
            <p>On the <strong>front end</strong>: Public routes (landing, login, register, features, pricing, docs, about, how-it-works, privacy, terms, contact) and protected routes (<code>/app</code> dashboard and settings, <code>/chat/:documentId</code>) with <code>ProtectedRoute</code> and hydration-aware redirect. Auth flow (login/register, API integration, Zustand with persistence, token in headers and for SSE). Documents (dashboard list, upload with drag-and-drop and file picker, progress polling, errors). Chat (per-document messages, user/assistant, markdown, sources; streaming via <code>streamChat()</code> with delta/done parsing; typing indicator; optional auto-scroll; abort on unmount/logout). Settings (account, preferences like auto-scroll and show sources, system info; persisted prefs). Landing (hero, features, CTA, footer, navbar; Framer Motion and bubble background; reduced-motion hook). App shell (layout, sidebar, header, backend health banner, runtime config for API URL). Error handling across auth, API, and SSE.</p>
        </section>

        <section class="case-study-section">
            <h2>What I learned</h2>
            <p class="tldr">RAG is a system design problem. Retrieval quality drives answer quality more than the LLM. SSE with POST + auth is doable and keeps the API clean. Hybrid retrieval and progress UX make the product feel solid.</p>
            <p>RAG isn’t just “retrieval plus generation”—it’s an <strong>architecture</strong>. If retrieval is weak, even a strong LLM will underperform. Get chunking, embeddings, and hybrid search right, and a simpler model can still deliver good, grounded answers. I learned to treat retrieval as a first-class subsystem: ownership checks, DONE enforcement, and re-ranking all matter.</p>
            <p>Streaming chat over SSE with POST and Bearer auth was a deliberate choice. It keeps the API RESTful (one streaming endpoint, clear semantics) and avoids the limits of EventSource. Handling abort on unmount and logout keeps the client and server in sync.</p>
            <p>Hybrid retrieval (dense + lexical) improved relevance over vector-only search, especially for exact terms and mixed queries. Letting users see sources (chunk indices and scores) built trust and made debugging easier.</p>
            <p>Making LLM and embedding providers configurable meant I could test with stubs, run locally with Ollama, and switch to OpenAI or Gemini for production without rewriting the pipeline. That replaceability is something I’ll carry into other AI projects.</p>
        </section>

        <section class="case-study-section">
            <h2>Portfolio one-liner</h2>
            <p><strong>DocuMind (Insight Garden)</strong> — Full-stack document RAG SaaS: React (Vite, TypeScript, Zustand, shadcn/ui) + NestJS (Prisma, pgvector, BullMQ, Redis). Users upload PDFs; async jobs chunk and embed into PostgreSQL/pgvector; hybrid retrieval + configurable LLM power streaming chat with source attribution. Deployed: frontend on <strong>Vercel</strong>, backend on <strong>Railway</strong>, database on <strong>Supabase</strong>, Redis on <strong>Upstash</strong>. JWT auth, protected routes, SSE streaming, health and error handling throughout.</p>
        </section>

        <div style="margin-top: 60px; padding-top: 30px; border-top: 1px solid #262626;">
            <a href="../index.html#portfolio" class="back-link">← Back to Work</a>
        </div>
    </div>
    
    <script>
        (function() {
            'use strict';
            
            var lightbox = document.getElementById('imageLightbox');
            var lightboxImage = document.getElementById('lightboxImage');
            var closeButton = lightbox.querySelector('.lightbox-close');
            var backdrop = lightbox.querySelector('.lightbox-backdrop');
            var scrollPosition = 0;
            var isOpen = false;
            var lastClickedImage = null;
            
            function openLightboxWithImage(imgEl, e) {
                if (e) e.preventDefault();
                if (isOpen) return;
                
                lastClickedImage = imgEl;
                scrollPosition = window.pageYOffset || document.documentElement.scrollTop;
                lightboxImage.src = imgEl.src;
                lightboxImage.alt = imgEl.alt;
                lightbox.removeAttribute('hidden');
                document.body.style.overflow = 'hidden';
                document.body.style.paddingRight = window.innerWidth - document.documentElement.clientWidth + 'px';
                isOpen = true;
                
                requestAnimationFrame(function() {
                    closeButton.focus();
                });
            }
            
            function closeLightbox(e) {
                if (e && e.target !== backdrop && e.target !== closeButton && e.target !== lightboxImage) {
                    return;
                }
                if (!isOpen) return;
                
                lightbox.setAttribute('hidden', '');
                document.body.style.overflow = '';
                document.body.style.paddingRight = '';
                isOpen = false;
                
                window.scrollTo({
                    top: scrollPosition,
                    behavior: 'auto'
                });
                
                requestAnimationFrame(function() {
                    if (lastClickedImage) lastClickedImage.focus();
                });
            }
            
            var clickableImages = document.querySelectorAll('.hero-image-clickable');
            clickableImages.forEach(function(img) {
                img.addEventListener('click', function(e) {
                    openLightboxWithImage(this, e);
                });
                img.addEventListener('keydown', function(e) {
                    if (e.key === 'Enter' || e.key === ' ') {
                        openLightboxWithImage(this, e);
                    }
                });
            });
            
            closeButton.addEventListener('click', closeLightbox);
            backdrop.addEventListener('click', closeLightbox);
            
            function handleEscape(e) {
                if (e.key === 'Escape' && isOpen) {
                    closeLightbox();
                }
            }
            document.addEventListener('keydown', handleEscape);
            
            lightbox.addEventListener('keydown', function(e) {
                if (e.key !== 'Tab') return;
                
                var focusableElements = lightbox.querySelectorAll('button, [tabindex]:not([tabindex="-1"])');
                if (focusableElements.length === 0) return;
                
                var firstElement = focusableElements[0];
                var lastElement = focusableElements[focusableElements.length - 1];
                var activeElement = document.activeElement;
                
                if (e.shiftKey) {
                    if (activeElement === firstElement) {
                        e.preventDefault();
                        lastElement.focus();
                    }
                } else {
                    if (activeElement === lastElement) {
                        e.preventDefault();
                        firstElement.focus();
                    }
                }
            });
        })();
    </script>
</body>
</html>
